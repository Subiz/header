// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package logan

@SerialVersionUID(0L)
final case class Debug(
    memStats: scala.Option[logan.MemStats] = None,
    numCpu: _root_.scala.Int = 0,
    numGoroutine: _root_.scala.Int = 0,
    stackTrace: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
    hostname: _root_.scala.Predef.String = "",
    kafka: scala.Option[logan.KafkaInfo] = None
    ) extends scalapb.GeneratedMessage with scalapb.Message[Debug] with scalapb.lenses.Updatable[Debug] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      if (memStats.isDefined) { __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(memStats.get.serializedSize) + memStats.get.serializedSize }
      if (numCpu != 0) { __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, numCpu) }
      if (numGoroutine != 0) { __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(4, numGoroutine) }
      if (stackTrace != _root_.com.google.protobuf.ByteString.EMPTY) { __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(5, stackTrace) }
      if (hostname != "") { __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(6, hostname) }
      if (kafka.isDefined) { __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(kafka.get.serializedSize) + kafka.get.serializedSize }
      __size
    }
    final override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      memStats.foreach { __v =>
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__v.serializedSize)
        __v.writeTo(_output__)
      };
      {
        val __v = numCpu
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      {
        val __v = numGoroutine
        if (__v != 0) {
          _output__.writeInt32(4, __v)
        }
      };
      {
        val __v = stackTrace
        if (__v != _root_.com.google.protobuf.ByteString.EMPTY) {
          _output__.writeBytes(5, __v)
        }
      };
      {
        val __v = hostname
        if (__v != "") {
          _output__.writeString(6, __v)
        }
      };
      kafka.foreach { __v =>
        _output__.writeTag(23, 2)
        _output__.writeUInt32NoTag(__v.serializedSize)
        __v.writeTo(_output__)
      };
    }
    def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): logan.Debug = {
      var __memStats = this.memStats
      var __numCpu = this.numCpu
      var __numGoroutine = this.numGoroutine
      var __stackTrace = this.stackTrace
      var __hostname = this.hostname
      var __kafka = this.kafka
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 18 =>
            __memStats = Option(_root_.scalapb.LiteParser.readMessage(_input__, __memStats.getOrElse(logan.MemStats.defaultInstance)))
          case 24 =>
            __numCpu = _input__.readInt32()
          case 32 =>
            __numGoroutine = _input__.readInt32()
          case 42 =>
            __stackTrace = _input__.readBytes()
          case 50 =>
            __hostname = _input__.readString()
          case 186 =>
            __kafka = Option(_root_.scalapb.LiteParser.readMessage(_input__, __kafka.getOrElse(logan.KafkaInfo.defaultInstance)))
          case tag => _input__.skipField(tag)
        }
      }
      logan.Debug(
          memStats = __memStats,
          numCpu = __numCpu,
          numGoroutine = __numGoroutine,
          stackTrace = __stackTrace,
          hostname = __hostname,
          kafka = __kafka
      )
    }
    def getMemStats: logan.MemStats = memStats.getOrElse(logan.MemStats.defaultInstance)
    def clearMemStats: Debug = copy(memStats = None)
    def withMemStats(__v: logan.MemStats): Debug = copy(memStats = Option(__v))
    def withNumCpu(__v: _root_.scala.Int): Debug = copy(numCpu = __v)
    def withNumGoroutine(__v: _root_.scala.Int): Debug = copy(numGoroutine = __v)
    def withStackTrace(__v: _root_.com.google.protobuf.ByteString): Debug = copy(stackTrace = __v)
    def withHostname(__v: _root_.scala.Predef.String): Debug = copy(hostname = __v)
    def getKafka: logan.KafkaInfo = kafka.getOrElse(logan.KafkaInfo.defaultInstance)
    def clearKafka: Debug = copy(kafka = None)
    def withKafka(__v: logan.KafkaInfo): Debug = copy(kafka = Option(__v))
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 2 => memStats.orNull
        case 3 => {
          val __t = numCpu
          if (__t != 0) __t else null
        }
        case 4 => {
          val __t = numGoroutine
          if (__t != 0) __t else null
        }
        case 5 => {
          val __t = stackTrace
          if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
        }
        case 6 => {
          val __t = hostname
          if (__t != "") __t else null
        }
        case 23 => kafka.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 2 => memStats.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => _root_.scalapb.descriptors.PInt(numCpu)
        case 4 => _root_.scalapb.descriptors.PInt(numGoroutine)
        case 5 => _root_.scalapb.descriptors.PByteString(stackTrace)
        case 6 => _root_.scalapb.descriptors.PString(hostname)
        case 23 => kafka.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = logan.Debug
}

object Debug extends scalapb.GeneratedMessageCompanion[logan.Debug] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[logan.Debug] = this
  def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, scala.Any]): logan.Debug = {
    require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
    val __fields = javaDescriptor.getFields
    logan.Debug(
      __fieldsMap.get(__fields.get(0)).asInstanceOf[scala.Option[logan.MemStats]],
      __fieldsMap.getOrElse(__fields.get(1), 0).asInstanceOf[_root_.scala.Int],
      __fieldsMap.getOrElse(__fields.get(2), 0).asInstanceOf[_root_.scala.Int],
      __fieldsMap.getOrElse(__fields.get(3), _root_.com.google.protobuf.ByteString.EMPTY).asInstanceOf[_root_.com.google.protobuf.ByteString],
      __fieldsMap.getOrElse(__fields.get(4), "").asInstanceOf[_root_.scala.Predef.String],
      __fieldsMap.get(__fields.get(5)).asInstanceOf[scala.Option[logan.KafkaInfo]]
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[logan.Debug] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      logan.Debug(
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[scala.Option[logan.MemStats]]),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(23).get).flatMap(_.as[scala.Option[logan.KafkaInfo]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = LoganProto.javaDescriptor.getMessageTypes.get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = LoganProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = logan.MemStats
      case 23 => __out = logan.KafkaInfo
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = logan.Debug(
  )
  implicit class DebugLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, logan.Debug]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, logan.Debug](_l) {
    def memStats: _root_.scalapb.lenses.Lens[UpperPB, logan.MemStats] = field(_.getMemStats)((c_, f_) => c_.copy(memStats = Option(f_)))
    def optionalMemStats: _root_.scalapb.lenses.Lens[UpperPB, scala.Option[logan.MemStats]] = field(_.memStats)((c_, f_) => c_.copy(memStats = f_))
    def numCpu: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.numCpu)((c_, f_) => c_.copy(numCpu = f_))
    def numGoroutine: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.numGoroutine)((c_, f_) => c_.copy(numGoroutine = f_))
    def stackTrace: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.stackTrace)((c_, f_) => c_.copy(stackTrace = f_))
    def hostname: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.hostname)((c_, f_) => c_.copy(hostname = f_))
    def kafka: _root_.scalapb.lenses.Lens[UpperPB, logan.KafkaInfo] = field(_.getKafka)((c_, f_) => c_.copy(kafka = Option(f_)))
    def optionalKafka: _root_.scalapb.lenses.Lens[UpperPB, scala.Option[logan.KafkaInfo]] = field(_.kafka)((c_, f_) => c_.copy(kafka = f_))
  }
  final val MEM_STATS_FIELD_NUMBER = 2
  final val NUM_CPU_FIELD_NUMBER = 3
  final val NUM_GOROUTINE_FIELD_NUMBER = 4
  final val STACK_TRACE_FIELD_NUMBER = 5
  final val HOSTNAME_FIELD_NUMBER = 6
  final val KAFKA_FIELD_NUMBER = 23
}
