// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package logan

@SerialVersionUID(0L)
final case class KafkaInfo(
    topic: _root_.scala.Predef.String = "",
    partition: _root_.scala.Int = 0,
    offset: _root_.scala.Long = 0L
    ) extends scalapb.GeneratedMessage with scalapb.Message[KafkaInfo] with scalapb.lenses.Updatable[KafkaInfo] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      if (topic != "") { __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, topic) }
      if (partition != 0) { __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, partition) }
      if (offset != 0L) { __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, offset) }
      __size
    }
    final override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = topic
        if (__v != "") {
          _output__.writeString(2, __v)
        }
      };
      {
        val __v = partition
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      {
        val __v = offset
        if (__v != 0L) {
          _output__.writeInt64(4, __v)
        }
      };
    }
    def mergeFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): logan.KafkaInfo = {
      var __topic = this.topic
      var __partition = this.partition
      var __offset = this.offset
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 18 =>
            __topic = _input__.readString()
          case 24 =>
            __partition = _input__.readInt32()
          case 32 =>
            __offset = _input__.readInt64()
          case tag => _input__.skipField(tag)
        }
      }
      logan.KafkaInfo(
          topic = __topic,
          partition = __partition,
          offset = __offset
      )
    }
    def withTopic(__v: _root_.scala.Predef.String): KafkaInfo = copy(topic = __v)
    def withPartition(__v: _root_.scala.Int): KafkaInfo = copy(partition = __v)
    def withOffset(__v: _root_.scala.Long): KafkaInfo = copy(offset = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 2 => {
          val __t = topic
          if (__t != "") __t else null
        }
        case 3 => {
          val __t = partition
          if (__t != 0) __t else null
        }
        case 4 => {
          val __t = offset
          if (__t != 0L) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 2 => _root_.scalapb.descriptors.PString(topic)
        case 3 => _root_.scalapb.descriptors.PInt(partition)
        case 4 => _root_.scalapb.descriptors.PLong(offset)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion = logan.KafkaInfo
}

object KafkaInfo extends scalapb.GeneratedMessageCompanion[logan.KafkaInfo] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[logan.KafkaInfo] = this
  def fromFieldsMap(__fieldsMap: scala.collection.immutable.Map[_root_.com.google.protobuf.Descriptors.FieldDescriptor, scala.Any]): logan.KafkaInfo = {
    require(__fieldsMap.keys.forall(_.getContainingType() == javaDescriptor), "FieldDescriptor does not match message type.")
    val __fields = javaDescriptor.getFields
    logan.KafkaInfo(
      __fieldsMap.getOrElse(__fields.get(0), "").asInstanceOf[_root_.scala.Predef.String],
      __fieldsMap.getOrElse(__fields.get(1), 0).asInstanceOf[_root_.scala.Int],
      __fieldsMap.getOrElse(__fields.get(2), 0L).asInstanceOf[_root_.scala.Long]
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[logan.KafkaInfo] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      require(__fieldsMap.keys.forall(_.containingMessage == scalaDescriptor), "FieldDescriptor does not match message type.")
      logan.KafkaInfo(
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = LoganProto.javaDescriptor.getMessageTypes.get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = LoganProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = logan.KafkaInfo(
  )
  implicit class KafkaInfoLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, logan.KafkaInfo]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, logan.KafkaInfo](_l) {
    def topic: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.topic)((c_, f_) => c_.copy(topic = f_))
    def partition: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.partition)((c_, f_) => c_.copy(partition = f_))
    def offset: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.offset)((c_, f_) => c_.copy(offset = f_))
  }
  final val TOPIC_FIELD_NUMBER = 2
  final val PARTITION_FIELD_NUMBER = 3
  final val OFFSET_FIELD_NUMBER = 4
}
